Le danger du «machine learning» dénoncé par le Conseil de stabilité financière


Les potentialités de l’intelligence artificielle et du « machine learning » dans la finance sont indéniables, mais quel est l’impact de ces technologies sur la stabilité financière ? C’est la question que le Conseil de stabilité financière (FSB), l’organe chargé de détecter les grandes menaces qui pèsent sur la finance mondiale et de préconiser les réformes, s’est posée dans un rapport publié ce mercredi. Dans ses conclusions, le FSB n'échappe pas à l’enthousiasme général vis-à-vis de ces technologies qui pourrait engager une nouvelle révolution industrielle dans les services financiers : « ces technologies peuvent permettre un traitement plus efficace des données sur les risques de crédit qui serait bénéfique au système financier dans son ensemble ». Mais, l’organe de régulation qui rassemble des représentants de la Fed et de la BCE pointe aussi les nouveaux risques que ces technologies mettent à jour : l’empressement des acteurs financiers à s'équiper d’outils d’intelligence artificielle pourrait orienter leur vision des risques financiers dans une même direction et in fine, « amplifier les chocs financiers ». « Considéré dans leur ensemble, la vulnérabilité des banques universelles aux risques systémiques pourrait s’accroître si elles développent leur dépendance à des algorithmes similaires ou des schémas d’exploitation de données comparables », précise encore le FSB. Des défis de compréhension à relever En cas de choc financier, d’autres effets collatéraux sont encore à anticiper : « beaucoup de modèles conçus à partir d’intelligence artificielle ou de «machine learning» ont été entraînés et testés pendant des périodes de volatilité faibles sur les marchés, ils risquent donc de ne pas prendre les décisions optimales en cas de retournement économique majeur », craint le FSB. Enfin, la complexité croissante de ces technologies représente aussi un risque en soi : « des représentants de l’industrie interrogés par le FSB ont pointé la difficulté d’auditer de façon efficace ces outils, indiquant parfois des difficultés quant à disposer de ressources internes capables de comprendre et de superviser ces logiciels d’intelligence artificielle auto apprenant ». Dans ce contexte et compte tenu du potentiel de ces technologies pour améliorer la qualité des crédits, l’efficacité des marchés financiers ou encore la détection des fraudes, le FSB appelle à un examen approfondi de ces innovations. « Il est important que les progrès de l’intelligence artificielle aillent de pair avec les progrès de l’interprétation des résultats des algorithmes utilisés et de leurs implications ». Retrouvez l’intégralité de l’article sur le site des Échos