La Californie fait cavalier seul dans la régulation de l’IA


L’État de Californie, berceau mondial du développement de la tech, s’apprête à voter une loi pionnière visant à réguler les puissants modèles d’intelligence artificielle. Alors que l’Union européenne vient d’adopter son propre AI Act, le Congrès américain peine à adopter son futur projet de loi destiné à encadrer les usages de l’intelligence artificielle (IA). L’Etat de Californie pourrait le devancer : il est en train d’adopter son propre texte, baptisé «SB-1047» (SB pour Senate Bill, projet de loi du Sénat). Ce texte ambitionne d’encadrer l’IA générative, soit les outils permettant de générer des contenus comme des textes ou des images sur simple requête en langage courant, ainsi que le développement des grands modèles de langage (LLM). Il «vise à garantir le développement sûr de systèmes d’intelligence artificielle à grande échelle en établissant des normes de sécurité claires, prévisibles et de bon sens pour les développeurs des systèmes d’IA», précise le texte en préambule. Et surtout à prévenir, pour empêcher les grands modèles d’IA de provoquer des catastrophes majeures ou des incidents de cybersécurité. «S’ils ne sont pas correctement soumis aux contrôles humains, les prochains développements de l’intelligence artificielle pourraient être utilisés pour créer de nouvelles menaces à la sûreté et à la sécurité publiques, en permettant notamment la création et la prolifération d’armes de destruction massive, telles que des armes biologiques, chimiques et nucléaires», alerte ainsi d’emblée le texte SB-1047, avec des accents dystopiques. Un projet de loi modifié à dix reprises Mais cette amorce de régulation de l’IA suscite d’intenses débats, voire une contestation, ses détracteurs estimant qu’elle pourrait freiner l’innovation et faire fuir les investisseurs. En particulier dans la Silicon Valley, où sont basées des jeunes stars de l’IA, telles OpenAI et Anthropic. Depuis ses débuts, le texte est porté par le sénateur démocrate de l'État de Californie, Scott Wiener, qui l’a coécrit avec trois autres sénateurs démocrates, Richard Roth, Susan Rubio et Henry Stern. Or depuis son dépôt au Sénat le 7 février dernier, le texte a subi une nuée d’amendements : il en est actuellement à sa dixième version, la dernière étant datée du 22 août . Cette dernière mouture accorde ainsi moins de pouvoir qu’initialement aux autorités californiennes pour contraindre les sociétés d’IA à rendre des comptes ou pour les poursuivre en justice. Si la loi était votée, les développeurs de grands modèles d’IA devraient toutefois tester leurs systèmes et simuler des cyberattaques, sous peine d’amende, mais sans la menace de conséquences pénales. La création d’une nouvelle agence de régulation a également été annulée, au profit d’un organisme qui aurait juste à déterminer des normes pour les modèles d’IA les plus avancés. Bataille d’influence dans la Silicon Valley Le 2 août dernier, la société de capital-risque Andreessen Horowitz, basée dans la Silicon Valley, écrivait au sénateur Wiener, taclant le projet de loi «tel qu’il est actuellement rédigé (…): il entravera l’innovation et l’investissement dans cette technologie émergente importante, affaiblira la position des États-Unis en tant que leader mondial de la technologie et créera des obstacles inutiles et arbitraires pour une industrie compétitive qui stimule la création d’emplois en Californie à une échelle record». Sans surprise, le fondateur d’OpenAI, Sam Altman, était lui aussi en première ligne : dans une lettre adressée courant août à Scott Wiener, il a pris position contre le texte «SB-1047», assurant pourrait faire fuir les innovateurs de l'État américain et de la Silicon Valley alors que «la révolution de l’IA commence à peine». Et il a préconisé une législation nationale plutôt qu’au niveau fédéral. Combler un vide juridique «Le Congrès [au niveau fédéral, NDLR] étant bloqué sur la réglementation de l’IA, la Californie doit agir pour anticiper les risques prévisibles présentés par les progrès rapides de l’IA tout en encourageant l’innovation», a rétorqué Scott Wiener dans un communiqué publié le 15 août. Pour sa part, Anthropic a salué le projet de loi amendé, «considérablement amélioré, au point que nous pensons que ses avantages l’emportent probablement sur ses coûts» , dans une lettre adressée le mercredi 21 août au gouverneur de Californie, Gavin Newsom. Plus étonnant, Elon Musk l’a aussi soutenu : le milliardaire libertarien – à la tête de sa propre entreprise d’IA xAI - estime que «tout bien considéré, la Californie devrait probablement adopter le projet de loi SB 1047 sur la sécurité de l’IA. Depuis plus de 20 ans, je suis un défenseur de la réglementation de l’IA, tout comme nous réglementons tout produit/technologie qui présente un risque potentiel pour le public» , relève-t-il lundi 27 août sur le réseau social X (ex-Twitter), dont il est propriétaire. This is a tough call and will make some people upset, but, all things considered, I think California should probably pass the SB 1047 AI safety bill. For over 20 years, I have been an advocate for AI regulation, just as we regulate any product/technology that is a potential risk… — Elon Musk (@elonmusk) August 26, 2024 Le sujet divise aussi les démocrates. «Beaucoup d’entre nous au Congrès pensent que la loi «SB-1047» est bien intentionnée, mais mal fondée», a ainsi écrit le 16 août, dans un communiqué , la très influente élue californienne et ex-présidente de la Chambre des représentants Nancy Pelosi. Bien qu’elle soutienne l’idée de réguler l’IA et de protéger les consommateurs, elle estime que le projet de loi actuel pourrait nuire à la position de leader de la Californie dans le domaine de l’IA. Le processus est dans sa dernière ligne droite. Le projet de loi «SB 1047» doit encore être présenté cette semaine à la Chambre basse californienne. S’il est adopté par le Sénat, il sera transmis à Gavin Newsom, qui décidera s’il le ratifie avant la fin du mois d’août - il n’a pas encore pris position publiquement sur le sujet.