Les modèles de scoring bancaires doivent se moderniser pour être plus pertinents


Philippe du Jardin, professeur de systèmes d’information, pôle de recherche en analyse financière et comptabilité, Edhec Business School Datant des années 1960, les premiers modèles de scoring bancaires ont connu, au fil du temps, plusieurs vagues d’amélioration dues notamment aux progrès de l’algorithmique et des techniques d’apprentissage. Or, malgré des avancées notables dans ces domaines, les institutions financières baignent toujours dans le monde statistique d’il y a 50 ans. Les modèles de scoring sont employés par les banques et les institutions financières pour estimer le risque de défaut de paiement de leurs débiteurs et ce, aussi bien pour des raisons commerciales que prudentielles. La faillite représentant l’élément déclencheur principal d’un défaut de paiement, et conduisant aux pertes les plus substantielles pour le créancier, ces modèles sont rapidement devenus des modèles de faillite ; prévoir un défaut revenait alors à prévoir l’occurrence de l’événement le plus dramatique pouvant le causer. A l’origine, un modèle s’exprimait sous la forme d’une équation simple où le risque était calculé grâce à une combinaison linéaire d’un certain nombre de ratios financiers choisis selon leur capacité à discriminer correctement les firmes susceptibles de disparaître et les autres. D’une certaine manière, une équation permettait de calculer une distance entre la situation financière d’une entreprise donnée, estimée à un moment donné de son existence, et un état prototypique de faillite. La probabilité de faillite était alors proportionnelle à l’étendue de l’écart entre les deux. Cette façon d’appréhender le risque est toujours en vigueur dans les institutions financières. La Banque de France d’ailleurs a largement documenté sa méthode fondée sur l’analyse discriminante dès les années 1980 et n’en a pas changé depuis. La simplicité d’élaboration des premiers modèles de scoring , comme d’ailleurs leur assez bonne efficacité, ont conduit assez rapidement à la généralisation de leur emploi. Mais ce qui a fait leur succès est aussi à l’origine de leurs principales limites. Tout d’abord, ces outils supposent que la relation entre les variables explicatives, donc les ratios financiers décrivant l’état d’un débiteur, et le risque, est linéaire, et que ces mêmes variables peuvent se compenser totalement, puisque le modèle est additif. Or les effets de seuil que l’on peut constater lorsque l’on observe la distribution des ratios montrent que la compensation ne fonctionne que sur une partie, parfois réduite, de celle-ci ; et ces mêmes effets de seuil font que la probabilité de défaut suit souvent une fonction dont la pente change de sens au voisinage de la valeur d’un seuil. Ensuite, ces modèles reposent sur des règles de classification uniques, chacun s’exprimant sous la forme d’une seule et même équation. L’état de faillite est alors réductible à un seul état critique de référence et le modèle incarne en quelque sorte la frontière entre celui-ci et un état de survie potentielle. Or on sait que la faillite est le résultat de processus divers, qui peuvent être longs à se mettre en place, et qui peuvent donner naissance à différents états ou différentes formes de déclin. C’est là que les techniques dites « ensemblistes » viennent corriger les insuffisances des solutions traditionnelles. Les techniques employées à cette fin ont pour objet de créer un méta-modèle dont chaque élément dispose d’une expertise particulière propre à une certaine région de l’espace de décision. Un ensemble est alors constitué de plusieurs dizaines ou centaines de modèles, conçus indépendamment ou non les uns des autres, et sa prévision est calculée en combinant les prévisions individuelles de chaque modèle. Enfin, les modèles de scoring s’appuient sur une vision le plus souvent statique des signes avant-coureurs de la faillite. En effet, les variables sont généralement estimées une seule fois et un an avant l’horizon des prévisions. Or, la faillite résulte d’une dynamique qui s’inscrit d’abord dans l’histoire des entreprises et ne peut donc être décrite correctement en l’absence de prise en compte de la dimension temporelle. C’est vraisemblablement là que réside la plus grande faiblesse des modèles bancaires. Là encore, certains d’entre eux qui permettent d’appréhender l’évolution de la situation financière des entreprises au cours du temps conduisent à de meilleures prévisions que ceux obtenus par les modèles bancaires. Les trois types de modélisation (non linéaires, ensemblistes, historiques) ne sont pas mutuellement exclusifs, et peuvent se combiner. Tout cela montre bien l’étendue de l’écart existant entre les pratiques des établissements financiers et la réalité des techniques modernes d’estimation du risque de défaut. {"title":"la plus grande faiblesse des mod\u00e8les bancaires tient au manque de prise en compte de la dimension temporelle»,"name":"","body":"","image":0,"legend":"","credit":""}