La Californie enterre son projet de loi sur l’IA


Le projet de loi californien destiné à encadrer les usages autour de l’intelligence artificielle (IA) générative semble plus que jamais avoir du plomb dans l’aile. Le gouverneur démocrate de l’Etat, Gavin Newsom, y a mis son veto, dimanche 29 septembre, au terme de plusieurs mois de contestations virulentes de la part des géants technologiques, directement concernés par ce projet. Le gouverneur estime que cette réglementation aurait imposé «des normes strictes, même pour les fonctions les plus élémentaires» lors de l’utilisation d’un grand modèle. Le projet de loi «SB 1047» sur la sécurité de l’intelligence artificielle, aussi controversé que pionnier, aurait posé les bases d’un encadrement de l’IA générative, soit des outils permettant de générer des contenus comme des textes ou des images sur simple requête en langage courant, ainsi que le développement des grands modèles de langage (LLM), en établissant «des normes de sécurité claires» pour les développeurs. Rendre les développeurs d’IA responsables Il aurait été un des premiers à rendre les développeurs responsables de tout préjudice grave causé par leur technologie. Il aurait aussi exigé que les entreprises développant des modèles d’IA puissants puissent désactiver leurs technologies en cas de risques de dommages majeurs, tels que des pertes humaines massives ou des dégâts matériels supérieurs à 500 millions de dollars (448 millions d’euros). Cette actualité est scrutée bien au-delà du cocon tech de la Californie. Car toute décision prise dans le berceau de la très influente Silicon Valley pourrait faire école aux Etats-Unis, voire au-delà. S’il avait été adopté, le SB 1047 serait devenu le fondement de la réglementation de l’IA aux États-Unis. Il est aussi scruté dans un contexte où les législateurs du monde entier sont confrontés au même défi, avec l’IA aujourd’hui comme avec d’autres technologies par le passé : contrôler les risques de l’IA sans brider l’innovation, soit en accompagnant les technologies émergentes. Aux Etats-Unis, Washington est embourbé avec son futur projet de loi destiné à encadrer les usages de l’IA, qu’il peine à faire adopter. L’Europe, de son côté, a certes adopté cette année son propre AI Act. Mais son entrée en application est loin d’être un long fleuve tranquille : plusieurs Big Tech freinent des quatre fers pour s’y conformer, Meta et Apple en tête, qui prétextent une «difficile réglementation» européenne, y englobant aussi le Digital Markets Act (DMA). Ils ont repoussé sine die, cet été, la mise à disposition en Europe de leurs propres assistants virtuels (chatbots) respectifs, Apple Intelligence et Meta AI. Meta a enfoncé le clou la semaine dernière dans une lettre ouverte. Durant tout l’été, l’évolution de ce texte porté par le sénateur démocrate de l'État de Californie, Scott Wiener a donc été scruté, et a subi une nuée d’amendements, la dixième version du texte était adoptée le 28 août . Ne pas compromettre la Californie, «leader mondial de l’IA» Toute entreprise faisant des affaires en Californie était concernée. Alors pendant tout l’été, les champions de la tech et élus (démocrates) se sont déchirés sur ce texte. Google, Meta, Microsoft et OpenAI avaient bruyamment exprimé leurs inquiétudes, affirmant que ce texte imposait des normes vagues au nom de la sécurité et pourrait bloquer l’innovation dans l’Etat. Les informaticiens Geoffrey Hinton et Yoshua Bengio, qui ont développé une grande partie de la technologie sur laquelle repose la vague actuelle d’IA générative, en étaient eux aussi de fervents partisans. En outre, 119 employés actuels et anciens des plus grandes entreprises d’IA ont signé une lettre demandant son adoption. En revanche, plusieurs poids lourds du parti démocrate comme Nancy Pelosi, ancienne présidente du Congrès, et le maire de San Francisco London Breed, se sont exprimés contre, cet été. Gavin Newsom les a finalement suivis. Premier signal, déjà cet été, il avait déclaré qu’il souhaitait protéger le statut de la Californie en tant que leader mondial de l’IA, soulignant que 32 des 50 plus grandes entreprises d’IA au monde sont situées dans l'État. L’encadrement proposé était peut-être trop rigide. «Demander de comprendre a priori comment les IA seront utilisées est impossible. Comme tous les outils, elles peuvent être utilisées à bon ou à mauvais escient. Les applications évoluent, la créativité humaine est telle qu’elles sont impossibles à anticiper» , précise à L’Agefi l’ingénieur Luc Julia, le co-créateur de Siri. Autre projet de loi L’auteur du projet de loi, Scott Wiener, sénateur démocrate de San Francisco, a qualifié le veto de Gavin Newsom de «revers pour tous ceux qui croient en la surveillance des grandes entreprises qui prennent des décisions critiques affectant la sécurité et le bien-être du public et l’avenir de la planète» . Pour autant, ce dernier ne ferme pas la porte à une amorce de régulation. Il a annoncé qu’il travaillait avec d'éminents chercheurs en IA, dont Fei-Fei Li, professeur à l’université de Stanford qui a travaillé chez Google, pour élaborer une nouvelle législation qu’il est prêt à soutenir. En outre, Gavin Newsom a promulgué cette année d’autres projets de loi plus ciblés liés à l’IA, en particulier pour lutter contre les deepfakes (vidéos truquées avec de l’IA) liées aux élections, et dans l’industrie du cinéma pour donner aux artistes plus de contrôle sur leurs répliques numériques.