L’AFG éclaire les sociétés de gestion sur l’AI Act


Depuis son entrée en vigueur le 1ᵉʳ août 2024, l’AI Act pose les bases d’un cadre réglementaire européen inédit pour encadrer l’utilisation de l’intelligence artificielle. Avec des premières échéances majeures dès février 2025, les sociétés de gestion d’actifs sont confrontées à des exigences croissantes de gouvernance, de transparence et d’explicabilité. Pour accompagner ses membres, l’Association française de la gestion (AFG) a dévoilé un guide détaillé qui aborde les étapes clés de la mise en conformité, tout en mettant en lumière les opportunités que ces technologies offrent au secteur. « Même si l’industrie de la gestion d’actifs est déjà soumise à de nombreuses réglementations, l’AI Act doit être perçue comme un pas en avant pour inciter à une prise de conscience et à une meilleure maîtrise des outils d’IA. Aujourd’hui, les sociétés de gestion intègrent, au même titre que le risque cyber, l’impact opérationnel des outils d’IA qu’elles utilisent ou développent », commente l’association professionnelle. Le calendrier de l’AI Act structure les priorités des sociétés de gestion sur plusieurs années. La première échéance est imminente : le 2 février marque l’interdiction des systèmes présentant des risques inacceptables et l’obligation pour les systèmes à risque limité de respecter des exigences minimales de transparence. Puis, le 2 août 2025, vient la mise en œuvre des obligations de gouvernance et de documentation pour les modèles d’IA à usage général. A lire aussi: IA Act, la gestion d’actifs en quête de clarté Une gouvernance adaptée Face à ces échéances, le guide de l’AFG met un accent particulier sur la nécessité de cartographier les outils et systèmes d’IA déployés par les sociétés de gestion. « L'échelle des risques prévue par l’AI Act montre bien que les systèmes d’IA utilisés par les sociétés de gestion, sont classifiés principalement dans les catégories risques faibles ou limités », souligne Muriel Faure, présidente de la commission Innovation technologique de l’AFG. Cette cartographie inclut des outils variés, allant des algorithmes d’aide à la décision dans la gestion de portefeuille aux systèmes automatisés de reporting. Dans ce dernier cas, les sociétés de gestion utilisant des modèles de traitement automatique du langage (NLP) doivent s’assurer que les résultats générés répondent aux exigences d’explicabilité imposées par l’AI Act. Au-delà de la cartographie, le guide met en lumière l’importance d’une gouvernance adaptée pour encadrer l’utilisation de l’IA. Les outils doivent être soumis à des mécanismes de contrôle humain, notamment pour éviter les biais algorithmiques susceptibles de fausser les décisions. « L’une des clés de réussite du développement des cas d’usage consiste en la maîtrise de la qualité des données utilisées, sa quantité (pour “entraîner” les modèles) et la sécurisation de ces données », rappelle Thomas Valli, directeur des études économiques de l’AFG. A lire aussi: L’AI Act, texte pionnier pour réguler l’intelligence artificielle, entre en vigueur Le document propose également des recommandations concrètes pour répondre aux exigences de transparence. Par exemple, les systèmes automatisés qui interagissent directement avec les clients – tels que les chatbots – devront être signalés comme tels, avec une mention explicite de leur nature non humaine. Cette obligation s’aligne sur le principe de transparence prévu par l’AI Act. Le guide souligne aussi que les gérants devront être capables d’expliquer les décisions prises par les algorithmes. Dans le cadre de la gestion d’actifs, cela pourrait inclure la documentation des modèles utilisés pour sélectionner certains investissements ou évaluer les performances ESG. Une adoption encore inégale L’AFG propose plusieurs cas d’usage pour illustrer l’impact potentiel de l’IA dans le secteur. L’un des exemples mis en avant concerne l’utilisation d’algorithmes pour analyser des données non structurées, comme des rapports ESG ou des actualités économiques, afin d’affiner les décisions d’investissement. Dans le domaine de la conformité, les systèmes d’IA peuvent également automatiser la détection d’anomalies dans les transactions, réduisant ainsi les coûts opérationnels associés aux vérifications manuelles. Cependant, le guide rappelle que ces outils doivent être accompagnés de procédures claires pour garantir leur traçabilité. Les gérants doivent en conséquence s’assurer que les prestataires externes respectent les normes imposées par l’AI Act, notamment en matière de documentation et de responsabilité partagée. Si les grandes sociétés de gestion françaises semblent bien positionnées pour intégrer ces nouvelles obligations, les structures plus modestes rencontrent davantage de difficultés. « Les grandes entreprises disposent déjà de ressources importantes pour innover et répondre aux exigences réglementaires. Pour les plus petites structures, l’intégration de l’IA reste souvent limitée par des moyens financiers et humains restreints », note un professionnel du secteur. « Les banques et assurances, souvent en contact direct avec les consommateurs, ont une longueur d’avance. En comparaison, les sociétés de gestion, principalement en B2B, doivent encore franchir un cap pour rattraper ce retard », ajoute-t-il. Le secteur montre tout de même quelques signes d’accélération. Ce 23 janvier, plus de 350 professionnels assistaient à une conférence exclusive organisée par l’AFG sur ce sujet, « un record » de participation, indique-t-on à L’Agefi.