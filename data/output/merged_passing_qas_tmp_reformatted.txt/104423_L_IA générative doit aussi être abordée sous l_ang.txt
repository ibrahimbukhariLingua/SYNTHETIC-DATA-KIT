L’IA générative doit aussi être abordée sous l’angle de la cybersécurité


Cette année, le colloque du Forum des Compétences avait pour thème «IA générative et cybersécurité», un sujet complexe qui a déjà donné lieu à la publication d’un document au printemps et à un webinaire il y a quelques semaines. Mais ce colloque était aussi l’occasion de recevoir Emmanuel Naëgelen, directeur adjoint de l’Anssi, l’Agence nationale de la sécurité des systèmes d’information, qui travaille également sur le sujet. A lire aussi: Le risque cyber exige des entreprises une organisation adaptée Des risques classiques « La cybersécurité des intelligences artificielles touche d’abord aux risques classiques d’intrusion, de fuite des données ou d’exfiltration des modèles, a-t-il exposé. Ce sont des sujets nouveaux sur lesquels nous n’avons pas encore les idées claires. » La cybersécurité face à l’IA peut être envisagée sous plusieurs angles : d’abord, celui de l’IA utilisée par les attaquants, comme pour produire des e-mails de phishing très réalistes qui sont d’autant plus redoutables. Mais aussi l’IA utilisée pour automatiser les attaques et les rendre évolutives, « un risque qui n’émerge pas encore », selon le directeur adjoint de l’Anssi, mais qui ne doit pas être négligé pour autant. Toutefois, la cybersécurité peut aussi tirer bénéfice de l’IA en améliorant les dispositifs de sécurité, et notamment en détectant les comportements anormaux. Dans ce domaine, l’IA a déjà fait ses preuves. L’Anssi s’est donné plusieurs missions pour diffuser et favoriser la prévention des risques liés à l’IA. Elle participe activement à l’organisation du prochain Sommet de l’IA qui se tiendra les 10 et 11 février prochains, et qui intégrera un cycle de conférences sur la cybersécurité. L’agence travaille justement sur l’analyse des risques des systèmes d’IA. Par ailleurs, l’Anssi accompagne la mise en œuvre du règlement européen sur l’IA (AI Act) et conseille les autorités de surveillance de marché. Elle se tient également à la disposition des prestataires de services et de produits de cybersécurité qui embarquent de l’IA, et adapte ses schémas de certification des produits et services de confiance. Enfin, l’agence continue de sensibiliser l’écosystème à la cybersécurité et à l’IA. A lire aussi: L’intelligence artificielle accroît la fragilité cyber des entreprises Ne pas faire confiance à l’IA générative Elle a déjà publié un Guide sur la sécurité des systèmes d’IA générative , en avril dernier, et travaillé avec son homologue allemand sur un guide sur les assistants de programmation qui embarquent de l’IA afin de générer du code plus rapidement. Ces travaux ont abouti à une recommandation importante : « Ne pas faire confiance au code généré par une IA et surtout préserver la place des codeurs humains expérimentés et capables de vérifier le code ainsi généré », a insisté Emmanuel Naëgelen. Par ailleurs, l’Anssi a également coopéré avec l’Allemagne sur la vérification d’identité à distance et publié un autre guide, qui fait aussi le point sur les « deep fakes » et sur l’impact de ces systèmes sur la cybersécurité. L’Anssi coopère également avec les autres régulateurs comme la Cnil (sujets liés aux données personnelles), l’ACPR (encadrement du secteur financier) et Viginum, un nouvel organisme émanant du secrétariat de la défense et de la sécurité nationale (SGDSN), chargé de la détection des ingérences informationnelles venues de l’étranger. « Pour le moment, on ne peut pas traiter de la sécurité des IA comme d’un sujet de conformité, avec des listes de points à mettre en œuvre , a souligné Emmanuel Naëgelen. Nous en sommes encore aux analyses de risques. Mais le secteur financier est très avant-gardiste sur ces questions-là. » A lire aussi: Le cloud expose les entreprises à un risque cyber accru Eviter tout anthropomorphisme Les autres intervenants du colloque, issus de consultants spécialisés ou d’institutions financières, ont montré l’avancée de leurs réflexions : 39% des entreprises utilisent déjà l’IA dans la cybersécurité, ce qui a déjà permis de réduire de 2,2 millions de dollars, soit plus d’un tiers, le coût des attaques cyber, selon Yoann Viaouët, lead emerging technologies & infrastructure security chez Deloitte Cyber. L’IA générative est ainsi déjà déployée dans la gestion des risques et la conformité, mais aussi dans la détection des menaces et les réponses ou encore dans la gestion des vulnérabilités et lors des tests. Des pratiques et des outils qui permettent aux RSSI (responsables de la sécurité des systèmes d’information) d’être « augmentés ». Mais les juristes présents, comme l’avocat François Coupez, fondateur du cabinet Level Up Legal, ont rappelé que les outils n’effacent jamais la responsabilité des hommes. « L’IA n’est qu’un outil dont on doit connaître les apports et les limites et surtout écarter tout anthropomorphisme, a-t-il résumé, sous peine de se faire truander » par un outil qui offre des résultats vraisemblables, peut-être, mais pas forcément vrais.