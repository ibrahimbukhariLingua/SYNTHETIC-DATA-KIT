L’Autorité de la concurrence alerte sur les risques concurrentiels inhérents à l’IA générative


La jeune industrie de l’intelligence artificielle (IA) générative soulève déjà des risques de pratiques potentiellement anti-concurrentielles. Dans un avis publié vendredi 28 juin, l’Autorité de la concurrence (ADLC) passe au crible ce secteur bouillonnant, qui attire déjà des milliards de dollars d’investissements . «L’IA générative est entrée dans le débat public avec ChatGPT [lancé par OpenAI en novembre 2022 ndlr] : c’est une technologie à usage général qui a des implications dans tous les secteurs de l’économie, pour la productivité et l’emploi» , résumait Benoît Coeuré, président de l’institution, lors d’une conférence de presse. «Il est dès lors essentiel que le fonctionnement concurrentiel permette la présence d’une multiplicité d’acteurs» , écrit l’Autorité dans son rapport. Avec pour spectre que l’IA générative ne renforce un peu plus encore la puissance des géants du numérique. Course de vitesse pour réguler L’Autorité a mis les bouchées doubles pour s’emparer du sujet au plus vite. Elle avait déjà frappé fort en menant en septembre 2023 une perquisition chez un fournisseur de puces IA - probablement Nvidia. Après s’être autosaisie du sujet en février, l’ADLC a lancé une consultation publique dans la foulée, et a mené cinq mois de consultations tambour battant, au cours desquels elle a auditionné plus de 50 entreprises, associations et homologues antitrust pour publier son «avis» ce vendredi, assorti de recommandations. A titre de comparaison, son avis sectoriel sur le marché du cloud avait, lui, demandé 18 mois de travail. Dans ce qui s’assimile à une course de vitesse, plusieurs des homologues de l’autorité de la Rue de L’Echelle se sont déjà emparées du sujet pour tenter de réguler l’IA générative. Déjà la FTC américaine, la CMA britannique, et le régulateur portugais ont publié leurs propres avis. Et vendredi après-midi, la Commission européenne annonçait passer au crible les liens entre Microsoft et OpenAI, prélude à une possible enquête approfondie. Il y a urgence : il faut éviter que ce jeune marché qui grossit à toute vitesse ne soit verrouillé par une poignée d’acteurs tels que OpenAI, Microsoft, Google et Meta. Tous ont déjà lancé leurs nouveaux services d’IA générative, avec en tête leurs agents conversationnels, tels que ChatGPT et Bard. Le «partenariat pluriannuel» estimé à 13 milliards noué entre Microsoft et OpenAI avait fait figure d’alerte. Intérêt général «La production de l’IA générative doit fonctionner de manière concurrentielle, c’est une question d’intérêt général», souligne Benoît Coeuré. Face à son nouvel essor dans le monde numérique, de «très grands acteurs» du secteur ont déjà planté leurs banderilles et ont un «accès privilégié aux intrants» nécessaires pour l’entraînement et le développement de modèles de langage, prévient-il. L’Autorité a identifié les principaux risques antitrust, au premier chef ceux d’abus au niveau des composants informatiques (fixation des prix, restrictions), de verrouillage par les grands fournisseurs de services cloud, ou encore l’exploitation sans autorisation de contenus des éditeurs (de presse notamment) par les fournisseurs de modèles de langages. Autre risque potentiel, celui de prises de participations minoritaires et partenariats des géants du numérique – comme avec le précédent Microsoft – OpenAI. Sur ces bases, l’instance a émis plusieurs recommandations : d’abord, élargir le nouveau règlement européen sur les services numériques (DMA) à l’IA générative. Elle suggère aussi un «développement des supercalculateurs publics» , dont au niveau européen, et de «permettre au plus grand nombre d’acteurs», dont des acteurs privés et start-up, «d’accéder à la puissance de calcul» de ces supercalculateurs moyennant rémunération, comme Jean Zay en France. Elle demande aussi plus de transparence dans les prises de participation minoritaires des géants de la tech dans les entreprises de l’IA.