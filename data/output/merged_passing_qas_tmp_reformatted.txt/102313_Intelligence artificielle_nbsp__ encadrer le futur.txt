Intelligence artificielle&nbsp;: encadrer le futur, le grand défi de l’Union européenne


En avril 2021, la présentation par la Commission européenne de sa proposition d’encadrement de l’usage et de la commercialisation des systèmes d’intelligence artificielle, l’«AI Act», avait principalement suscité l’intérêt d’un nombre réduit de spécialistes . Deux ans plus tard, l’engouement planétaire provoqué par le générateur de contenus rédactionnels ChatGPT a fait passer le sujet de l’ombre à la pleine lumière. L’AI Act est, du même coup, devenu prématurément obsolète, avant même son adoption. Pour les colégislateurs de l’Union européenne (UE) à Bruxelles, où le texte est toujours en discussion, l’enjeu est désormais de préparer ce cadre législatif inédit à travers le monde aux bouleversements technologiques dont le phénomène ChatGPT pourrait n’être qu’un simple présage. Dans sa propre version du projet, adoptée jeudi 11 mai en commission – à la suite du Conseil de l’UE en février –, le Parlement européen a tenté de relever cet immense défi. La structure de l’essentiel du texte concocté par la Commission reste inchangée. La majorité des systèmes d’intelligence artificielle (IA) se répartissent en quatre catégories. La première regroupe les IA qui présentent des risques jugés «inacceptables» , car, par exemple, menaçant les droits fondamentaux, et qui sont donc interdites. La liste est assez courte. Y figurent, par exemple, les systèmes de «score social», qui, à l’instar des méthodes de surveillance du pouvoir chinois, consistent en l’attribution d’une note aux citoyens en fonction de leur comportement. La deuxième catégorie regroupe les systèmes jugés à «hauts risques» . Une myriade de secteurs susceptibles d’être concernés ont été listés par la Commission : l’éducation et la formation professionnelle, l’emploi et la gestion des collaborateurs, l’accès aux services privés essentiels et aux services et prestations publics, l’application du droit, la gestion des migrations… Ces produits seront soumis à une série d’obligations réparties sur l’ensemble de leur cycle de développement, du développeur – avec un focus sur les données utilisées – à l’utilisateur professionnel, en passant par le distributeur. Leur commercialisation nécessitera une autorisation ex ante des autorités nationales, à l’issue d’un processus d’ «estimation, évaluation et préparation aux risques prévisibles» . Les deux dernières catégories concernent les IA à «risques faibles et limités» , auxquelles seront uniquement imposées des «règles de transparence» , et les IA «autorisées» , exemptes d’obligations spécifiques (les objets connectés du quotidien : montres, électroménager…). Mais une question très délicate se pose aux colégislateurs de l’UE depuis l’irruption de ChatGPT : dans quelle catégorie ranger ces IA dites à usage général (GPAIS, pour « general purpose AI systems »), dont font partie les IA génératives, type ChatGPT, qui créent des contenus originaux (images, texte) à partir d’importantes quantités de données existantes ? Le Parlement européen a proposé la création d’un «régime spécial» pour les encadrer. «Spécifiquement pour les IA génératives, certaines mesures de diligence devront être respectées sur la conception de l’algorithme, pour garantir que le contenu qu’il produit n’est pas contraire à la loi. Deuxièmement, le développeur devra faire la transparence totale sur tous les matériaux (musique, art, publications) soumis à des droits d’auteur qui auraient été utilisés pour entraîner l’algorithme. Charge ensuite aux détenteurs de ces droits d’auteur de décider s’ils veulent demander réparation» , a résumé Dragos Tudorache, eurodéputé (Renew, libéral) corapporteur du texte. L’UE peut-elle devenir un «acteur clé de l’IA» ? Interrogé sur les moyens de combattre la potentielle propagation massive de fake news ou de fausses images en ligne, le second rapporteur, Brando Benifei (S&D, centre-gauche), a rappelé «l’obligation d’éviter la génération de contenu illégal. Lorsque des images ou des textes ont été générés par des IA, cela devra apparaître clairement» , a-t-il ajouté, avant de conclure : «Il s’agit de la partie la plus récente de nos travaux, elle peut certainement être améliorée.» La réflexion pourrait en effet n’en être qu’à ses balbutiements. L’adoption du projet est espérée l’année prochaine, et des révisions seront possibles tous les six mois. Certains observateurs pointent déjà l’insuffisance des règles face aux dangers potentiels. «L’esprit du projet législatif est de s’appuyer en grande partie sur une autorégulation des acteurs économiques. Les mesures de diligence sont en fait assez souples» , explique Juliette Sénéchal, professeure de droit privé à l’université de Lille et autrice d’un article sur le sujet dans la revue juridique Dalloz . Le projet reste imparfait mais il permet à l’UE de se positionner en pionnière de l’encadrement de l’IA, comme elle l’a déjà fait au sujet des plateformes numériques, avec les projets de règlement sur les services numériques (DSA) et de règlement sur les marchés numériques (DMA) , et, avant cela, avec le RGPD, le règlement sur la protection des données personnelles, législation qui sert de modèle dans le monde entier. Mais, douloureux paradoxe, si l’UE se rêve en leader de la réglementation, elle accuse un retard que de nombreux spécialistes jugent irrattrapable en matière d’innovation face aux géants américains et chinois. L’espoir n’est pas pour autant proscrit : couplé à des investissements massifs, ce cadre législatif inédit pourrait faire partie d’une «stratégie de différenciation» permettant à l’Europe de devenir un «acteur clé de l’IA» , estime un rapport de l’Institut Montaigne, paru en avril . Le sujet est sensible car, outre les problèmes de sécurité, c’est le modèle même de société qui est remis en cause par l’intelligence artificielle.◆