Cinq nouvelles tendances sur l’utilisation des données dans la finance 


Les nouvelles technologies redéfinissent le secteur financier. Elles façonnent les produits proposés, les interactions clients et la manière dont les banques utilisent leurs nouvelles sources de données. Cette évolution est vouée à se poursuivre, alors voici cinq tendances fortes qui bouleversent la façon d’appréhender les données dans la finance. Tendance n° 1 : des services financiers accessibles « as-a-service » Transformer les capacités de back-office en services commercialisables est l’un des domaines les plus récents et à la croissance la plus rapide pour les organismes de services financiers traditionnels. Les FinTech, potentiellement compétitives, continuent de se multiplier et de tout chambouler. Elles ont constaté que leurs modèles agiles en matière d’engagement client devaient toujours s’appuyer sur les principes fondamentaux perfectionnés par les acteurs historiques. Alors pourquoi permettre à ces derniers d’accéder à ces services ? Les normes Open Banking, les services à la carte, ou encore les API, sont autant de nouvelles manières de mettre en œuvre la chaîne de valeur. Pour la plupart des organismes traditionnels, il est complexe d’atteindre ce niveau d’agilité, en particulier lorsque les métiers et leurs silos de données ne sont pas intégrés. Le data mesh encourage de nouvelles façons de réduire le temps et le coût de l’intégration des données. Ce concept permet aux entreprises d’utiliser leurs données in situ, facilitant ainsi la livraison des données nécessaires à la prise en charge d’API plus ouvertes. Tendance n° 2 : l’organisme financier comme fournisseur de services technologiques L’organisation est-elle une banque, ou une entreprise technologique de services bancaires ? Alors que les lignes se brouillent, les prestataires de services financiers traditionnels doivent mettre en œuvre de nouveaux types de produits et de services pour améliorer l’expérience de leurs clients et de leurs partenaires. L’identification de nouvelles opportunités pour créer de la valeur pour les clients commence par les données. Mais, avec une telle quantité de données disponibles, il est impossible de créer l’agilité nécessaire pour les intégrer et les digérer toutes, même lorsqu’elles se trouvent dans un data lake. La solution est de ne pas les intégrer en premier lieu, du moins physiquement. Les nouvelles techniques de virtualisation des données permettent de créer plus rapidement des ensembles de données sans avoir à déplacer les données de l’endroit où elles se trouvent, ce qui permet d'économiser du temps et de l’argent. Plus important encore, elles procurent de la souplesse dans la sélection de nouveaux ensembles de données, pour des analyses plus fines. Tendance n° 3 : une culture institutionnelle « data-driven » Des processus décisionnels fiables et efficaces nécessitent une formation sous-jacente à la gestion des données, souvent désignée par l’expression « culture data driven » (culture axée sur les données). Les initiatives visant à instaurer une telle culture aident les analystes à acquérir une plus grande confiance dans la recherche, l’accès, l’utilisation et l’interprétation des colossaux volumes de données. La démocratisation de l’accès données est le soutien d’un accès plus large à celles-ci et de leur utilisation dans l’ensemble de l’organisation. Toutefois, les cultures data-driven ne sont valables que dans la mesure où les organisations sont en mesure de fournir en temps voulu des données fiables. Il n’est pas toujours possible d’obtenir la convergence des propriétaires des différentes sources de données sur leur signification et sur la manière dont elles doivent être collectées et utilisées. Ce décalage crée des goulets d'étranglement au sein des organisations qui tentent d’intégrer des données dans des entrepôts de données traditionnels à des fins d’analyse. Une approche data mesh permet de surmonter ce problème en permettant aux entreprises de collecter des données à la demande, à partir des sources existantes. En supprimant la nécessité de déplacer les données, le nombre de silos est réduit et l’intégrité de la gouvernance des données est préservée. Tendance n° 4 : le jumeau numérique du client La connaissance des clients, l'évolution de leurs attentes, de leur environnement, de leurs relations, de leurs préférences, aide à automatiser les services, à évaluer l’intérêt pour de nouveaux produits, à analyser les risques et à prédire le taux de désaffection. Les données du jumeau numérique sont tirées des interactions réelles avec le client. En règle générale, plus les données recueillies sont nombreuses, plus le jumeau numérique est proche du client réel. Mais, la collecte de grandes quantités de données à partir de sources disparates ne permet pas de progresser rapidement avec les approches traditionnelles d’extraction, de transformation et de chargement (ETL). La virtualisation des données contribue à accélérer la mise sur le marché de la technologie des jumeaux numériques en surmontant les goulets d'étranglement associés aux méthodes traditionnelles d’intégration des données. Tendance n° 5 : monétisation des données Les bonnes données ont une bonne valeur commerciale, et la discipline de ces données, l’infonomie, soutient le mécanisme qui consiste à lier l’information à la valeur monétaire. Les sociétés de services financiers peuvent découvrir de nouvelles sources de revenus grâce à l’analyse de leurs données. De nombreuses banques partagent déjà des données avec leurs partenaires commerciaux, bien qu’elles soient principalement anonymisées, agrégées et synthétisées sous forme de tendances. Cependant, la possibilité d’ajouter de nouvelles sources de données, de trouver facilement, par exemple, des informations géographiques, météorologiques, pandémiques, relationnelles, rend les données plus précieuses d’un point de vue économique. L’approfondissement des sources de données est complexe lorsqu’il existe potentiellement des centaines de sources de données parmi lesquelles choisir. C’est là que les approches traditionnelles de la collecte de données, telles que l’ETL, deviennent inefficaces. La virtualisation des données est une solution alternative et plus rentable.