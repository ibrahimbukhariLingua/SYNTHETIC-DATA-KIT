La lutte contre les deepfakes doit s’intensifier 


Les attaques via les nouvelles technologies ont franchi un nouveau palier de sophistication avec les deepfakes . Ces contenus trompeurs sont rendus profondément crédibles par l’intelligence artificielle : avec l’IA et les applications deepfake , les pirates peuvent créer facilement du contenu audio et vidéo hyperréaliste en temps réel. Des études récentes ont montré que les deepfakes sont de plus en plus difficiles à détecter pour les humains. En 2022 déjà, 66 % des professionnels de la cybersécurité ont déclaré avoir vu des deepfakes exploités lors d’une cyberattaque ciblant principalement les employés par courrier électronique et messagerie mobile. En plus de pertes financières, d’espionnage d’entreprise, les deepfakes peuvent également servir à obtenir l’authentification d’une identité non autorisée à l’aide d’une confirmation visuelle ou auditive. Ou encore être utilisés pour commettre des vols d’identité, du harcèlement, nuire considérablement à la réputation d’une personne ou d’une organisation. Les deepfakes relèvent de la catégorie plus large des médias synthétiques et sont souvent utilisés pour créer des vidéos, des images, des fichiers audio et des textes crédibles et réalistes sur des événements qui n’ont jamais eu lieu. Ils sont très efficaces pour diffuser de la désinformation. Des mesures concrètes Les entreprises ne sont pas complètement démunies face à cet essor. Différentes stratégies leur permettent de se protéger contre les menaces modernes basées sur l’identité telles que les deepfakes . Bien sûr, il est essentiel de mettre en place une formation continue en cybersécurité pour tous les employés. En 2023, 74 % de toutes les violations impliquaient un élément humain. Avec une culture « Zero Trust », les organisations atténuent les attaques basées sur l’identité En mettant en œuvre des contrôles de sécurité et en adoptant une mentalité « Zero Trust », les organisations peuvent mieux prévenir et atténuer les attaques basées sur l’identité. Elles peuvent aussi réaliser des exercices d’intrusion deepfake : les tests de pénétration vidéo et audio deepfake permettent de reconstruire une véritable attaque. Les pirates éthiques peuvent alors évaluer l’efficacité des mesures de sécurité et des processus internes (c’est-à-dire les contrôles financiers), identifier les faiblesses potentielles et conseiller sur la manière de renforcer les défenses contre ces types d’attaques d’ingénierie sociale. Lorsqu’elle est mise en œuvre efficacement, l’authentification multifacteur (MFA) ajoute une couche de protection importante contre les accès non autorisés et garantit l’authenticité d’une identité. Seuls les identités et les comptes disposant d’un accès privilégié aux systèmes, aux données, aux applications et à d’autres ressources sensibles restent à sécuriser. Enfin, certaines caractéristiques peuvent encore aider les individus à identifier les deepfakes les moins convaincants, comme une mauvaise synchronisation labiale, des mouvements oculaires peu naturels ou un manque de clignement des yeux. Cependant, avec les améliorations apportées par l’IA, les organisations devront adopter des technologies et des stratégies modernes, telles que la détection et la réponse aux menaces d’identité (ITDR), qui peuvent agir de manière intelligente. Les entreprises doivent réévaluer leurs mesures de cybersécurité et leurs processus internes, car de plus en plus d’attaques modernes de ce type sont à venir.