IA Act, la gestion d’actifs en quête de clarté


L’adoption croissante de l’intelligence artificielle (IA) soulève de nombreux défis réglementaires. Adopté en 2023 par l’Union européenne, l’IA Act définit des normes strictes pour les systèmes d’IA selon quatre niveaux de risque, des « faibles » aux « inacceptables ». Par exemple, les outils utilisés pour le scoring de crédit et les analyses environnementales, sociales et de gouvernance (ESG) sont classés comme à « haut risque » et doivent respecter des normes strictes de transparence et d’auditabilité. « Les entreprises doivent prouver l’efficacité de leurs modèles tout en garantissant leur conformité avec des standards de transparence et de non-biais, notamment dans des domaines sensibles comme l’analyse ESG ou le scoring de crédit », souligne Olivier Vigna, délégué général adjoint de Paris Europlace. Dans le cas des analyses ESG, des biais dans les données ou les critères d’évaluation pourraient entraîner une mauvaise évaluation des entreprises en termes de durabilité, affectant ainsi la qualité du portefeuille d’investissement. En matière de scoring de crédit, des biais peuvent survenir si les données utilisées favorisent inconsciemment certains profils, par exemple en fonction du secteur d’activité ou de la géographie des emprunteurs, conduisant à une prise de décision discriminatoire. Robustesse des modèles Pour éviter autant que possible ces biais et mieux contrôler la gestion des risques, RAM Active Investments a opté pour le développement interne de ses modèles de gestion. La société de gestion utilise l’IA dans sa stratégie d’investissement depuis sa création. « Nous avons préféré développer nos modèles en interne pour éviter la dépendance aux fournisseurs externes, mais cela nécessite une expertise technique et des investissements importants », explique Nicolas Jamet, gérant de portefeuille. L’entreprise utilise des modèles de machine learning pour analyser une grande variété de données, y compris des informations non structurées telles que des nouvelles économiques et des rapports financiers, ce qui lui permet d’optimiser la gestion des risques. « L’IA est essentielle pour traiter la quantité de données que nous recevons, surtout avec l’évolution du marché et l’augmentation des sources d’informations non structurées », explique Nicolas Jamet. Toutefois, cette approche nécessite une gestion rigoureuse des données. « Le contrôle de la qualité des données est crucial pour garantir l’efficacité des modèles », précise-t-il. Une démarche interne permet à l’entreprise de mieux comprendre les mécanismes sous-jacents de ses modèles et de garantir leur conformité avec les exigences du marché. La régulation ne couvre pas entièrement l'évolution rapide de la technologie et des zones d’ombre demeurent, en particulier concernant la classification des outils d’IA en fonction de leur risque. OLIVIER VIGNA, délégué général adjoint de Paris Europlace Dans son activité de dette privée, Sienna IM utilise également l’IA pour optimiser la gestion des prêts aux PME. L’un des principaux usages de l’IA est l’automatisation des processus de scoring et la détection d’anomalies, notamment pour identifier des comportements suspects en matière de fraude ou de blanchiment d’argent. « L’IA nous aide à repérer des comportements qui sortent de l’ordinaire, ce que les contrôles manuels peinent à faire », précise Wissem Bourbia, directeur des financements granulaires chez Sienna IM. La société utilise également l’IA avec son outil SESAMm qui évalue les controverses ESG en analysant de vastes ensembles de données provenant de multiples sources. Sous l’angle de l’IA Act, cet outil pourrait être considéré à « haut risque » notamment en matière de gestion des biais, de transparence et d’auditabilité. « Chaque analyse est validée pour éviter tout biais algorithmique », assure cependant Wissem Bourbia. Modèles internes ou externes Les sociétés de gestion d’actifs doivent donc choisir entre développer leurs modèles d’IA en interne ou faire appel à des solutions tierces. « L’approche interne permet un contrôle total sur les processus et la conformité, mais nécessite un investissement en ressources humaines et technologiques », explique Olivier Vigna. A l’inverse, l’externalisation permet plus de flexibilité, mais expose les entreprises à une certaine dépendance envers les fournisseurs externes. Axa IM adopte de son côté une approche hybride, développant certains outils en interne tout en intégrant des solutions externes comme ChatGPT pour l’analyse de documents. Laurence Arnold, responsable de l’innovation chez Axa IM, l’assure : « Cette combinaison nous permet de contrôler nos données sensibles tout en restant agiles . » Encadrement plus large L’IA dans la gestion d’actifs est encadrée par des régulations qui vont au-delà de l’IA Act. Le Dora Act, adopté en 2022 ( lire aussi L’Enquête page 8 ), impose des exigences en matière de résilience numérique, obligeant les sociétés à garantir la continuité des services et la sécurité des systèmes d’IA face aux cyberattaques. Le Règlement général sur la protection des données (RGPD), en vigueur depuis 2018, impose des restrictions sur la collecte et le traitement des données personnelles, obligeant les entreprises à appliquer des protocoles stricts pour protéger les informations sensibles tout en exploitant les technologies d’IA. Enfin, bien qu’ambitieux, plusieurs aspects de l’IA Act restent flous et nécessiteraient des éclaircissements, selon les professionnels. « La régulation ne couvre pas entièrement l'évolution rapide de la technologie et des zones d’ombre demeurent, en particulier concernant la classification des outils d’IA en fonction de leur risque », rappelle Olivier Vigna. En outre, bien que des textes de niveau supérieur – comme les textes d’application spécifiques – soient attendus, le temps nécessaire à leur publication crée une incertitude qui rend leur application plus complexe.